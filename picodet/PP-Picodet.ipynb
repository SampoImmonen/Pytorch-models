{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "assisted-oxygen",
   "metadata": {},
   "source": [
    "# Notebook to build PP-PicoDet model with basic pytorch building blocks\n",
    "- https://arxiv.org/abs/2111.00902\n",
    "\n",
    "## Note new version picodetv2\n",
    "- https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.4/ppdet/modeling/architectures/picodet.py\n",
    "- LCNET backbone (https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.4/ppdet/modeling/backbones/lcnet.py)\n",
    "- LCPAN (https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.4/ppdet/modeling/necks/lc_pan.py)\n",
    "- picoheadv2 (https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.4/ppdet/modeling/heads/pico_head.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "disabled-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-soldier",
   "metadata": {},
   "source": [
    "# Backbone PPLCNET (https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.4/ppdet/modeling/backbones/lcnet.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "blond-protocol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 160, 160])\n"
     ]
    }
   ],
   "source": [
    "# utils \n",
    "NET_CONFIG = {\n",
    "    \"blocks2\":\n",
    "    #k, in_c, out_c, s, use_se\n",
    "    [[3, 16, 32, 1, False], ],\n",
    "    \"blocks3\": [\n",
    "        [3, 32, 64, 2, False],\n",
    "        [3, 64, 64, 1, False],\n",
    "    ],\n",
    "    \"blocks4\": [\n",
    "        [3, 64, 128, 2, False],\n",
    "        [3, 128, 128, 1, False],\n",
    "    ],\n",
    "    \"blocks5\": [\n",
    "        [3, 128, 256, 2, False],\n",
    "        [5, 256, 256, 1, False],\n",
    "        [5, 256, 256, 1, False],\n",
    "        [5, 256, 256, 1, False],\n",
    "        [5, 256, 256, 1, False],\n",
    "        [5, 256, 256, 1, False],\n",
    "    ],\n",
    "    \"blocks6\": [[5, 256, 512, 2, True], [5, 512, 512, 1, True]]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def make_divisible(v, divisor=8, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "class ConvBNLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_channels,\n",
    "                 filter_size,\n",
    "                 num_filters,\n",
    "                 stride,\n",
    "                 num_groups=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels=num_channels,\n",
    "                              out_channels=num_filters,\n",
    "                              kernel_size=filter_size,\n",
    "                              stride=stride,\n",
    "                              padding=(filter_size-1)//2,\n",
    "                              groups=num_groups,\n",
    "                              bias=False)\n",
    "        # in inference fuse to conv\n",
    "        self.bn = nn.BatchNorm2d(num_filters)\n",
    "        self.hardswish = nn.Hardswish()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.hardswish(x)\n",
    "        return x\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "    def __init__(self, channel, reduction=4):\n",
    "        super().__init__()\n",
    "        self.avg_pool= nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv1 = nn.Conv2d(in_channels=channel,\n",
    "                               out_channels=channel//reduction,\n",
    "                               kernel_size=1,\n",
    "                               stride=1,\n",
    "                               padding=0)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=channel//reduction,\n",
    "                               out_channels=channel,\n",
    "                               kernel_size=1,\n",
    "                               stride=1,\n",
    "                               padding=0)\n",
    "        self.hardsigmoid = nn.Hardsigmoid()\n",
    "    def forward(self, x):\n",
    "        idendity = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.hardsigmoid(x)\n",
    "        x = x*idendity\n",
    "        return x\n",
    "        \n",
    "        \n",
    "class DepthWiseSeparable(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_channels,\n",
    "                 num_filters,\n",
    "                 stride,\n",
    "                 dw_size=3,\n",
    "                 use_se=False):\n",
    "        super().__init__()\n",
    "        self.use_se = use_se\n",
    "        self.dw_conv = ConvBNLayer(num_channels=num_channels,\n",
    "                                   num_filters=num_channels,\n",
    "                                   filter_size=dw_size,\n",
    "                                   stride=stride,\n",
    "                                   num_groups=num_channels)\n",
    "        if use_se:\n",
    "            self.se = SEModule(num_channels)\n",
    "        self.pw_conv = ConvBNLayer(num_channels=num_channels,\n",
    "                                   filter_size=1,\n",
    "                                   num_filters=num_filters,\n",
    "                                   stride=1)\n",
    "    def forward(self, x):\n",
    "        x = self.dw_conv(x)\n",
    "        if self.use_se:\n",
    "            x = self.se(x)\n",
    "        x = self.pw_conv(x)\n",
    "        return x\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "test_scale = 1\n",
    "conv_bn = ConvBNLayer(num_channels=3,\n",
    "                      filter_size=3,\n",
    "                      num_filters=make_divisible(16*test_scale),\n",
    "                      stride=2)\n",
    "se_module = SEModule(make_divisible(16*test_scale))\n",
    "blocks2 = nn.Sequential(*[DepthWiseSeparable(\n",
    "                            num_channels=make_divisible(in_c*test_scale),\n",
    "                            num_filters=make_divisible(out_c*test_scale),\n",
    "                            dw_size=k,\n",
    "                            stride=s,\n",
    "                            use_se=se) for i, (k, in_c, out_c, s, se) in enumerate(NET_CONFIG[\"blocks2\"])])\n",
    "\n",
    "test_input = torch.randn(1, 3, 320, 320)\n",
    "test_out = conv_bn(test_input)\n",
    "test_out = blocks2(test_out)\n",
    "print(test_out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "identified-correction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 40, 40])\n",
      "torch.Size([1, 256, 20, 20])\n",
      "torch.Size([1, 512, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "class LCNet(nn.Module):\n",
    "    def __init__(self, scale=1.0, feature_maps=[3, 4, 5]):\n",
    "        super().__init__()\n",
    "        self.scale = scale\n",
    "        self.feature_maps = feature_maps\n",
    "        \n",
    "        out_channels = []\n",
    "        self.conv1 = ConvBNLayer(num_channels=3,\n",
    "                                 filter_size=3,\n",
    "                                 num_filters=make_divisible(16*scale),\n",
    "                                 stride=2)\n",
    "        self.blocks2 = nn.Sequential(*[DepthWiseSeparable(\n",
    "                            num_channels=make_divisible(in_c*scale),\n",
    "                            num_filters=make_divisible(out_c*scale),\n",
    "                            dw_size=k,\n",
    "                            stride=s,\n",
    "                            use_se=se) for i, (k, in_c, out_c, s, se) in enumerate(NET_CONFIG[\"blocks2\"])])\n",
    "        self.blocks3 = nn.Sequential(*[DepthWiseSeparable(\n",
    "                            num_channels=make_divisible(in_c*scale),\n",
    "                            num_filters=make_divisible(out_c*scale),\n",
    "                            dw_size=k,\n",
    "                            stride=s,\n",
    "                            use_se=se) for i, (k, in_c, out_c, s, se) in enumerate(NET_CONFIG[\"blocks3\"])])\n",
    "        \n",
    "        out_channels.append(make_divisible(NET_CONFIG[\"blocks3\"][-1][2]*scale))\n",
    "        \n",
    "        self.blocks4 = nn.Sequential(*[DepthWiseSeparable(\n",
    "                            num_channels=make_divisible(in_c*scale),\n",
    "                            num_filters=make_divisible(out_c*scale),\n",
    "                            dw_size=k,\n",
    "                            stride=s,\n",
    "                            use_se=se) for i, (k, in_c, out_c, s, se) in enumerate(NET_CONFIG[\"blocks4\"])])\n",
    "        \n",
    "        out_channels.append(make_divisible(NET_CONFIG[\"blocks4\"][-1][2]*scale))\n",
    "        \n",
    "        self.blocks5 = nn.Sequential(*[DepthWiseSeparable(\n",
    "                            num_channels=make_divisible(in_c*scale),\n",
    "                            num_filters=make_divisible(out_c*scale),\n",
    "                            dw_size=k,\n",
    "                            stride=s,\n",
    "                            use_se=se) for i, (k, in_c, out_c, s, se) in enumerate(NET_CONFIG[\"blocks5\"])])\n",
    "        \n",
    "        out_channels.append(make_divisible(NET_CONFIG[\"blocks5\"][-1][2]*scale))\n",
    "        \n",
    "        self.blocks6 = nn.Sequential(*[DepthWiseSeparable(\n",
    "                            num_channels=make_divisible(in_c*scale),\n",
    "                            num_filters=make_divisible(out_c*scale),\n",
    "                            dw_size=k,\n",
    "                            stride=s,\n",
    "                            use_se=se) for i, (k, in_c, out_c, s, se) in enumerate(NET_CONFIG[\"blocks6\"])])\n",
    "        \n",
    "        out_channels.append(make_divisible(NET_CONFIG[\"blocks6\"][-1][2]*scale))\n",
    "        self._out_channels = [\n",
    "            ch for idx, ch in enumerate(out_channels) if idx+2 in feature_maps]\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = inputs['image']\n",
    "        outs = []\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.blocks2(x)\n",
    "        x = self.blocks3(x)\n",
    "        outs.append(x)\n",
    "        x = self.blocks4(x)\n",
    "        outs.append(x)\n",
    "        x = self.blocks5(x)\n",
    "        outs.append(x)\n",
    "        x = self.blocks6(x)\n",
    "        outs.append(x)\n",
    "        outs = [o for i, o in enumerate(outs) if i+2 in self.feature_maps]\n",
    "        return outs\n",
    "\n",
    "backbone = LCNet()\n",
    "inp_t = torch.randn(1, 3, 320, 320)\n",
    "output = backbone({'image': inp_t})\n",
    "for t in output:\n",
    "    print(t.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-palace",
   "metadata": {},
   "source": [
    "# Detector Neck LCPan: (https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.4/ppdet/modeling/necks/lc_pan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-broadcast",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "pytorchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

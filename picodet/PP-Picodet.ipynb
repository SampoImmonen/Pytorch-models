{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "assisted-oxygen",
   "metadata": {},
   "source": [
    "# Notebook to build PP-PicoDet model with basic pytorch building blocks\n",
    "- https://arxiv.org/abs/2111.00902\n",
    "\n",
    "## Note new version picodetv2\n",
    "- https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.4/ppdet/modeling/architectures/picodet.py\n",
    "- LCNET backbone (https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.4/ppdet/modeling/backbones/lcnet.py)\n",
    "- LCPAN (https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.4/ppdet/modeling/necks/lc_pan.py)\n",
    "- picoheadv2 (https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.4/ppdet/modeling/heads/pico_head.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "disabled-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-soldier",
   "metadata": {},
   "source": [
    "# Backbone PPLCNET (https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.4/ppdet/modeling/backbones/lcnet.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "blond-protocol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 160, 160])\n"
     ]
    }
   ],
   "source": [
    "# utils \n",
    "NET_CONFIG = {\n",
    "    \"blocks2\":\n",
    "    #k, in_c, out_c, s, use_se\n",
    "    [[3, 16, 32, 1, False], ],\n",
    "    \"blocks3\": [\n",
    "        [3, 32, 64, 2, False],\n",
    "        [3, 64, 64, 1, False],\n",
    "    ],\n",
    "    \"blocks4\": [\n",
    "        [3, 64, 128, 2, False],\n",
    "        [3, 128, 128, 1, False],\n",
    "    ],\n",
    "    \"blocks5\": [\n",
    "        [3, 128, 256, 2, False],\n",
    "        [5, 256, 256, 1, False],\n",
    "        [5, 256, 256, 1, False],\n",
    "        [5, 256, 256, 1, False],\n",
    "        [5, 256, 256, 1, False],\n",
    "        [5, 256, 256, 1, False],\n",
    "    ],\n",
    "    \"blocks6\": [[5, 256, 512, 2, True], [5, 512, 512, 1, True]]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def make_divisible(v, divisor=8, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "class ConvBNLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_channels,\n",
    "                 filter_size,\n",
    "                 num_filters,\n",
    "                 stride,\n",
    "                 num_groups=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels=num_channels,\n",
    "                              out_channels=num_filters,\n",
    "                              kernel_size=filter_size,\n",
    "                              stride=stride,\n",
    "                              padding=(filter_size-1)//2,\n",
    "                              groups=num_groups,\n",
    "                              bias=False)\n",
    "        # in inference fuse to conv\n",
    "        self.bn = nn.BatchNorm2d(num_filters)\n",
    "        self.hardswish = nn.Hardswish()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.hardswish(x)\n",
    "        return x\n",
    "\n",
    "class SEModule(nn.Module):\n",
    "    def __init__(self, channel, reduction=4):\n",
    "        super().__init__()\n",
    "        self.avg_pool= nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv1 = nn.Conv2d(in_channels=channel,\n",
    "                               out_channels=channel//reduction,\n",
    "                               kernel_size=1,\n",
    "                               stride=1,\n",
    "                               padding=0)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=channel//reduction,\n",
    "                               out_channels=channel,\n",
    "                               kernel_size=1,\n",
    "                               stride=1,\n",
    "                               padding=0)\n",
    "        self.hardsigmoid = nn.Hardsigmoid()\n",
    "    def forward(self, x):\n",
    "        idendity = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.hardsigmoid(x)\n",
    "        x = x*idendity\n",
    "        return x\n",
    "        \n",
    "        \n",
    "class DepthWiseSeparable(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_channels,\n",
    "                 num_filters,\n",
    "                 stride,\n",
    "                 dw_size=3,\n",
    "                 use_se=False):\n",
    "        super().__init__()\n",
    "        self.use_se = use_se\n",
    "        self.dw_conv = ConvBNLayer(num_channels=num_channels,\n",
    "                                   num_filters=num_channels,\n",
    "                                   filter_size=dw_size,\n",
    "                                   stride=stride,\n",
    "                                   num_groups=num_channels)\n",
    "        if use_se:\n",
    "            self.se = SEModule(num_channels)\n",
    "        self.pw_conv = ConvBNLayer(num_channels=num_channels,\n",
    "                                   filter_size=1,\n",
    "                                   num_filters=num_filters,\n",
    "                                   stride=1)\n",
    "    def forward(self, x):\n",
    "        x = self.dw_conv(x)\n",
    "        if self.use_se:\n",
    "            x = self.se(x)\n",
    "        x = self.pw_conv(x)\n",
    "        return x\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "test_scale = 1\n",
    "conv_bn = ConvBNLayer(num_channels=3,\n",
    "                      filter_size=3,\n",
    "                      num_filters=make_divisible(16*test_scale),\n",
    "                      stride=2)\n",
    "se_module = SEModule(make_divisible(16*test_scale))\n",
    "blocks2 = nn.Sequential(*[DepthWiseSeparable(\n",
    "                            num_channels=make_divisible(in_c*test_scale),\n",
    "                            num_filters=make_divisible(out_c*test_scale),\n",
    "                            dw_size=k,\n",
    "                            stride=s,\n",
    "                            use_se=se) for i, (k, in_c, out_c, s, se) in enumerate(NET_CONFIG[\"blocks2\"])])\n",
    "\n",
    "test_input = torch.randn(1, 3, 320, 320)\n",
    "test_out = conv_bn(test_input)\n",
    "test_out = blocks2(test_out)\n",
    "print(test_out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "identified-correction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 40, 40])\n",
      "torch.Size([1, 256, 20, 20])\n",
      "torch.Size([1, 512, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "class LCNet(nn.Module):\n",
    "    def __init__(self, scale=1.0, feature_maps=[3, 4, 5]):\n",
    "        super().__init__()\n",
    "        self.scale = scale\n",
    "        self.feature_maps = feature_maps\n",
    "        \n",
    "        out_channels = []\n",
    "        self.conv1 = ConvBNLayer(num_channels=3,\n",
    "                                 filter_size=3,\n",
    "                                 num_filters=make_divisible(16*scale),\n",
    "                                 stride=2)\n",
    "        self.blocks2 = nn.Sequential(*[DepthWiseSeparable(\n",
    "                            num_channels=make_divisible(in_c*scale),\n",
    "                            num_filters=make_divisible(out_c*scale),\n",
    "                            dw_size=k,\n",
    "                            stride=s,\n",
    "                            use_se=se) for i, (k, in_c, out_c, s, se) in enumerate(NET_CONFIG[\"blocks2\"])])\n",
    "        self.blocks3 = nn.Sequential(*[DepthWiseSeparable(\n",
    "                            num_channels=make_divisible(in_c*scale),\n",
    "                            num_filters=make_divisible(out_c*scale),\n",
    "                            dw_size=k,\n",
    "                            stride=s,\n",
    "                            use_se=se) for i, (k, in_c, out_c, s, se) in enumerate(NET_CONFIG[\"blocks3\"])])\n",
    "        \n",
    "        out_channels.append(make_divisible(NET_CONFIG[\"blocks3\"][-1][2]*scale))\n",
    "        \n",
    "        self.blocks4 = nn.Sequential(*[DepthWiseSeparable(\n",
    "                            num_channels=make_divisible(in_c*scale),\n",
    "                            num_filters=make_divisible(out_c*scale),\n",
    "                            dw_size=k,\n",
    "                            stride=s,\n",
    "                            use_se=se) for i, (k, in_c, out_c, s, se) in enumerate(NET_CONFIG[\"blocks4\"])])\n",
    "        \n",
    "        out_channels.append(make_divisible(NET_CONFIG[\"blocks4\"][-1][2]*scale))\n",
    "        \n",
    "        self.blocks5 = nn.Sequential(*[DepthWiseSeparable(\n",
    "                            num_channels=make_divisible(in_c*scale),\n",
    "                            num_filters=make_divisible(out_c*scale),\n",
    "                            dw_size=k,\n",
    "                            stride=s,\n",
    "                            use_se=se) for i, (k, in_c, out_c, s, se) in enumerate(NET_CONFIG[\"blocks5\"])])\n",
    "        \n",
    "        out_channels.append(make_divisible(NET_CONFIG[\"blocks5\"][-1][2]*scale))\n",
    "        \n",
    "        self.blocks6 = nn.Sequential(*[DepthWiseSeparable(\n",
    "                            num_channels=make_divisible(in_c*scale),\n",
    "                            num_filters=make_divisible(out_c*scale),\n",
    "                            dw_size=k,\n",
    "                            stride=s,\n",
    "                            use_se=se) for i, (k, in_c, out_c, s, se) in enumerate(NET_CONFIG[\"blocks6\"])])\n",
    "        \n",
    "        out_channels.append(make_divisible(NET_CONFIG[\"blocks6\"][-1][2]*scale))\n",
    "        self._out_channels = [\n",
    "            ch for idx, ch in enumerate(out_channels) if idx+2 in feature_maps]\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = inputs['image']\n",
    "        outs = []\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.blocks2(x)\n",
    "        x = self.blocks3(x)\n",
    "        outs.append(x)\n",
    "        x = self.blocks4(x)\n",
    "        outs.append(x)\n",
    "        x = self.blocks5(x)\n",
    "        outs.append(x)\n",
    "        x = self.blocks6(x)\n",
    "        outs.append(x)\n",
    "        outs = [o for i, o in enumerate(outs) if i+2 in self.feature_maps]\n",
    "        return outs\n",
    "\n",
    "backbone = LCNet()\n",
    "inp_t = torch.randn(1, 3, 320, 320)\n",
    "output = backbone({'image': inp_t})\n",
    "for t in output:\n",
    "    print(t.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-palace",
   "metadata": {},
   "source": [
    "# Detector Neck LCPan: (https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.4/ppdet/modeling/necks/lc_pan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "toxic-circular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96, 255, 255])\n",
      "torch.Size([1, 96, 255, 255])\n",
      "torch.Size([1, 96, 255, 255])\n",
      "torch.Size([1, 96, 25, 25])\n"
     ]
    }
   ],
   "source": [
    "class ConvBNLayerPAN(nn.Module):\n",
    "    \"\"\"\n",
    "    In Paddle Paddle there is two modules\n",
    "    named ConvBNLayer so we name this ConvBNLayerPAN\n",
    "    to separate the two\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "             in_channel=96,\n",
    "             out_channel=96,\n",
    "             kernel_size=3,\n",
    "             stride=1,\n",
    "             groups=1,\n",
    "             act='leaky_relu'):\n",
    "        super(ConvBNLayerPAN, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channel,\n",
    "            out_channels=out_channel,\n",
    "            kernel_size=kernel_size,\n",
    "            groups=groups,\n",
    "            padding=(kernel_size - 1) // 2,\n",
    "            stride=stride,\n",
    "            bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channel)\n",
    "        \n",
    "        self.has_act = False\n",
    "        if act:\n",
    "            self.has_act = True\n",
    "            \n",
    "        self.act = nn.LeakyReLU()\n",
    "        if act == \"hard_swish\":\n",
    "            self.act = nn.Hardswish()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn(self.conv(x))\n",
    "        if self.act:\n",
    "            x = self.act(x)\n",
    "        return x\n",
    "    \n",
    "class Channel_T(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=[116, 232, 464],\n",
    "                 out_channels=96,\n",
    "                 act=\"leaky_relu\"):\n",
    "        super(Channel_T, self).__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        for channel_count in in_channels:\n",
    "            self.convs.append(ConvBNLayerPAN(channel_count, out_channels, 1, act=act))\n",
    "    def forward(self, x):\n",
    "        outs = [self.convs[i](x[i]) for i in range(len(x))]\n",
    "        return outs\n",
    "            \n",
    "class DPModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Depth-wise and point-wise module.\n",
    "     Args:\n",
    "        in_channel (int): The input channels of this Module.\n",
    "        out_channel (int): The output channels of this Module.\n",
    "        kernel_size (int): The conv2d kernel size of this Module.\n",
    "        stride (int): The conv2d's stride of this Module.\n",
    "        act (str): The activation function of this Module,\n",
    "                   Now support `leaky_relu` and `hard_swish`.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "             in_channel=96,\n",
    "             out_channel=96,\n",
    "             kernel_size=3,\n",
    "             stride=1,\n",
    "             act='leaky_relu',\n",
    "             use_act_in_out=True):\n",
    "        super(DPModule, self).__init__()\n",
    "        self.use_act = False\n",
    "        if act:\n",
    "            self.use_act = True\n",
    "        self.use_act_in_out = use_act_in_out\n",
    "        self.dwconv = nn.Conv2d(\n",
    "            in_channels=in_channel,\n",
    "            out_channels=out_channel,\n",
    "            kernel_size=kernel_size,\n",
    "            groups=out_channel,\n",
    "            padding=(kernel_size - 1) // 2,\n",
    "            stride=stride,\n",
    "            bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.pwconv = nn.Conv2d(\n",
    "            in_channels=out_channel,\n",
    "            out_channels=out_channel,\n",
    "            kernel_size=1,\n",
    "            groups=1,\n",
    "            padding=0,\n",
    "            bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "        self.act_func = nn.LeakyReLU()\n",
    "        if act == \"hard_swish\":\n",
    "            self.act_func = nn.Hardswish()\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.dwconv(x))\n",
    "        if self.use_act:\n",
    "            x = self.act_func(x)\n",
    "        x = self.bn2(self.pwconv(x))\n",
    "        if self.use_act_in_out:\n",
    "            x = self.act_func(x)\n",
    "        return x\n",
    "            \n",
    "# test Channel_T\n",
    "channel_t = Channel_T(act='hard_swish')\n",
    "inp = [torch.randn(1, c, 255, 255) for c in [116, 232, 464]]\n",
    "out = channel_t(inp)\n",
    "for t in out:\n",
    "    print(t.size())\n",
    "\n",
    "# test DPModule\n",
    "dp_module = DPModule()\n",
    "inp = torch.randn(1, 96, 25, 25)\n",
    "out = dp_module(inp)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "entitled-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LCPAN(nn.Module):\n",
    "    \"\"\"Path Aggregation Network with LCNet module.\n",
    "    Args:\n",
    "        in_channels (List[int]): Number of input channels per scale.\n",
    "        out_channels (int): Number of output channels (used at each scale)\n",
    "        kernel_size (int): The conv2d kernel size of this Module.\n",
    "        num_features (int): Number of output features of CSPPAN module.\n",
    "        num_csp_blocks (int): Number of bottlenecks in CSPLayer. Default: 1\n",
    "        use_depthwise (bool): Whether to depthwise separable convolution in\n",
    "            blocks. Default: True\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size=5,\n",
    "                 num_features=3,\n",
    "                 use_depthwise=True,\n",
    "                 act='hard_swish',\n",
    "                 spatial_scales=[0.125, 0.0625, 0.03125]):\n",
    "        super(LCPAN, self).__init__()\n",
    "        self.conv_t = Channel_T(in_channels, out_channels, act=act)\n",
    "        in_channels = [out_channels]*len(spatial_scales)\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.spatial_scales = spatial_scales\n",
    "        self.num_features = num_features\n",
    "        conv_func = DPModule if use_depthwise else ConvBNLayer\n",
    "        \n",
    "        NET_CONFIG = {\n",
    "            #k, in_c, out_c, stride, use_se\n",
    "            \"block1\": [\n",
    "                [kernel_size, out_channels * 2, out_channels * 2, 1, False],\n",
    "                [kernel_size, out_channels * 2, out_channels, 1, False],\n",
    "            ],\n",
    "            \"block2\": [\n",
    "                [kernel_size, out_channels * 2, out_channels * 2, 1, False],\n",
    "                [kernel_size, out_channels * 2, out_channels, 1, False],\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        if self.num_features == 4:\n",
    "            self.first_top_conv = conv_func(\n",
    "                in_channels[0], in_channels[0], kernel_size, stride=2, act=act)\n",
    "            self.second_top_conv = conv_func(\n",
    "                in_channels[0], in_channels[0], kernel_size, stride=2, act=act)\n",
    "            self.spatial_scales.append(self.spatial_scales[-1] / 2)\n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.top_down_blocks = nn.ModuleList()\n",
    "        for idx in range(len(in_channels)-1 , 0, -1):\n",
    "            self.top_down_blocks.append(nn.Sequential(*[\n",
    "                DepthWiseSeparable(num_channels=in_c,\n",
    "                                   num_filters=out_c,\n",
    "                                   dw_size=k,\n",
    "                                   stride=s,\n",
    "                                   use_se=se) for i, (k, in_c, out_c, s, se) in enumerate(NET_CONFIG['block1'])\n",
    "            ]))\n",
    "            \n",
    "        self.downsamples = nn.ModuleList()\n",
    "        self.bottom_up_blocks = nn.ModuleList()\n",
    "        \n",
    "        for idx in range(len(in_channels)-1):\n",
    "            self.downsamples.append(conv_func(in_channels[idx],\n",
    "                                              in_channels[idx],\n",
    "                                              kernel_size=kernel_size,\n",
    "                                              stride=2,\n",
    "                                              act=act))\n",
    "            self.bottom_up_blocks.append(nn.Sequential(*[\n",
    "                DepthWiseSeparable(num_channels=in_c,\n",
    "                                   num_filters=out_c,\n",
    "                                   dw_size=k,\n",
    "                                   stride=s,\n",
    "                                   use_se=se) for i, (k, in_c, out_c, s, se) in enumerate(NET_CONFIG[\"block2\"])\n",
    "            ]))\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs (tuple[Tensor]): input features.\n",
    "        Returns:\n",
    "            tuple[Tensor]: CSPPAN features.\n",
    "        \"\"\"\n",
    "        \n",
    "        assert len(inputs) == len(self.in_channels)\n",
    "        inputs = self.conv_t(inputs)\n",
    "        \n",
    "        # top-down path\n",
    "        inner_outs = [inputs[-1]]\n",
    "        for idx in range(len(self.in_channels)-1, 0, -1):\n",
    "            feat_heigh = inner_outs[0] #(sic)\n",
    "            feat_low = inputs[idx-1]\n",
    "            \n",
    "            upsample_feat = self.upsample(feat_heigh)\n",
    "            \n",
    "            inner_out = self.top_down_blocks[len(self.in_channels)-1-idx](\n",
    "                torch.cat((upsample_feat, feat_low), dim=1))\n",
    "            inner_outs.insert(0, inner_out)\n",
    "        \n",
    "        # bottom-up path\n",
    "        outs = [inner_outs[0]]\n",
    "        for idx in range(len(self.in_channels)-1):\n",
    "            feat_low = outs[-1]\n",
    "            feat_height = inner_outs[idx+1]\n",
    "            downsample_feat = self.downsamples[idx](feat_low)\n",
    "            out = self.bottom_up_blocks[idx](\n",
    "                torch.cat((downsample_feat, feat_height), dim=1))\n",
    "\n",
    "            outs.append(out)\n",
    "        \n",
    "        top_features = None\n",
    "        if self.num_features == 4:\n",
    "            top_features = self.first_top_conv(inputs[-1])\n",
    "            top_features = top_features+self.second_top_conv(outs[-1])\n",
    "            outs.append(top_features)\n",
    "        return tuple(outs)\n",
    "lcpan = LCPAN(in_channels=[128, 256, 512], out_channels=96)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-mouth",
   "metadata": {},
   "source": [
    "# Test backbone plus LCPAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "funded-cache",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96, 40, 40])\n",
      "torch.Size([1, 96, 20, 20])\n",
      "torch.Size([1, 96, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "# model config\n",
    "scale = 0.75\n",
    "feature_maps = [3, 4, 5]\n",
    "out_channels = 96\n",
    "\n",
    "backbone = LCNet(scale, feature_maps)\n",
    "# get backbone output shape\n",
    "outputs = backbone({'image': torch.randn(1, 3, 320, 320)})\n",
    "in_channels = [c.size()[1] for c in outputs]\n",
    "\n",
    "neck = LCPAN(in_channels, out_channels)\n",
    "outputs = neck(outputs)\n",
    "for out in outputs:\n",
    "    print(out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-purchase",
   "metadata": {},
   "source": [
    "# PicoHeadV2: https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.4/ppdet/modeling/heads/pico_head.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "pytorchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
